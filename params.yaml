data-preprocess:
  vocab_size: 30000
  sequence_len: 150
  embedding_dim: 300

model-training:
  batch_size: 32
  epochs: 3
  val_split: 0.2
